{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e24bb0f8-1059-4100-bb45-f52501089d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.62      0.69        16\n",
      "           1       0.25      0.40      0.31         5\n",
      "\n",
      "    accuracy                           0.57        21\n",
      "   macro avg       0.51      0.51      0.50        21\n",
      "weighted avg       0.65      0.57      0.60        21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "import re\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "base_dir = r\"G:\\fraud_document_ai\\data\\processed\\thresholded\"\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "def extract_features(img):\n",
    "    edges = cv2.Canny(img, 100, 200)\n",
    "    edge_density = np.sum(edges > 0) / edges.size\n",
    "\n",
    "    contours, _ = cv2.findContours(\n",
    "        img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "    )\n",
    "    contour_count = len(contours)\n",
    "\n",
    "    text = pytesseract.image_to_string(img)\n",
    "    has_total = 1 if \"Total\" in text else 0\n",
    "    amount_count = len(re.findall(r\"\\d+[.,]\\d+\", text))\n",
    "\n",
    "    return [edge_density, contour_count, has_total, amount_count]\n",
    "\n",
    "for label, class_id in [(\"genuine\", 0), (\"fraud\", 1)]:\n",
    "    folder = os.path.join(base_dir, label)\n",
    "    for file in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder, file), cv2.IMREAD_GRAYSCALE)\n",
    "        feats = extract_features(img)\n",
    "        X.append(feats)\n",
    "        y.append(class_id)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "model = LogisticRegression(class_weight=\"balanced\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6233be1-5387-44c5-bc9e-2efe79cf820a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ade8dec-8818-4d28-b38b-2abd7db726c9",
   "metadata": {},
   "source": [
    "**The system fuses textual inconsistencies from OCR with visual anomaly features to classify fraudulent documents.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8909e1f0-b4ec-4f7a-b2f0-e4ba4f05fcfd",
   "metadata": {},
   "source": [
    "CLASSIFICATION REPORT TERMS\n",
    "\n",
    "0 → Genuine documents  \n",
    "1 → Fraud documents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd248b3-80e6-41f9-b4b5-23fba9217675",
   "metadata": {},
   "source": [
    "PRECISION\n",
    "What it means:\n",
    "\n",
    "• Out of everything the model predicted as this class, how many were correct\n",
    "\n",
    "Example:\n",
    "\n",
    "Precision = 0.77 for class 0\n",
    "\n",
    "• When the model says \"Genuine\", it is correct 77% of the time\n",
    "\n",
    "Why it matters:\n",
    "\n",
    "• Low precision → many false alarms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eada47e1-c3a9-47de-bbcd-3afa8092fe00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2eacc1f8-be07-4c51-ab5b-afa530e99870",
   "metadata": {},
   "source": [
    "RECALL\n",
    "\n",
    "What it means:\n",
    "\n",
    "• Out of all actual documents of this class, how many were correctly found\n",
    "\n",
    "Example:\n",
    "Recall = 0.40 for class 1\n",
    "\n",
    "• Out of all real fraud documents, 40% were detected\n",
    "\n",
    "Why it matters:\n",
    "\n",
    "• Low recall → fraud is being missed (bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39777752-8925-4538-8505-a1eee32c0f8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2680865-c96f-4ec2-b772-f03ccb682368",
   "metadata": {},
   "source": [
    "F1-SCORE\n",
    "\n",
    "What it means:\n",
    "\n",
    "• Single score combining precision and recall\n",
    "• Balance between false alarms and missed cases\n",
    "\n",
    "Formula:\n",
    "\n",
    "F1 = 2 × (Precision × Recall) / (Precision + Recall)\n",
    "\n",
    "Why it matters:\n",
    "\n",
    "• Useful when data is imbalanced (like fraud detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73204074-ca5c-45e0-8301-e28f5766b3f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7bd6afeb-3b16-44a4-9edb-3b20435b6bd6",
   "metadata": {},
   "source": [
    "SUPPORT\n",
    "\n",
    "What it means:\n",
    "• Number of true samples of that class in the test set\n",
    "\n",
    "Example:\n",
    "Support = 5 for class 1\n",
    "\n",
    "• There were 5 fraud documents in the test data\n",
    "\n",
    "Why it matters:\n",
    "    \n",
    "• Small support → metrics can fluctuate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d038aab-6797-42be-8f36-80fc585838b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f63111bb-2f2d-4b64-b575-d80abab04a66",
   "metadata": {},
   "source": [
    "HOW TO READ YOUR OUTPUT\n",
    "\n",
    "Class 0 (Genuine):\n",
    "\n",
    "• Precision 0.77 → genuine predictions are mostly correct\n",
    "• Recall 0.62 → some genuine docs flagged as fraud (acceptable)\n",
    "\n",
    "Class 1 (Fraud):\n",
    "\n",
    "• Precision 0.25 → some false alarms exist\n",
    "• Recall 0.40 → 2 out of 5 frauds detected (success)\n",
    "\n",
    "Final meaning:\n",
    "\n",
    "• Model detects fraud\n",
    "• Accepts some mistakes on genuine docs\n",
    "• Correct behavior for fraud detection systems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2139a2-fe8e-4048-ae96-db5cfaea1a40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
