{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "nb16-0001",
            "metadata": {},
            "source": [
                "# Notebook 16 — CNN Retraining on Balanced Dataset\n",
                "## Trains `fraud_document_cnn.h5` on the new `dataset/` 60/20/20 split\n",
                "\n",
                "**Target:** ≥85% validation accuracy  \n",
                "**Input:** `dataset/train/` and `dataset/val/`  \n",
                "**Output:** `models/fraud_document_cnn.h5` (overwritten with better weights)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "nb16-0002",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from pathlib import Path\n",
                "\n",
                "import tensorflow as tf\n",
                "from tensorflow.keras import layers, models, callbacks\n",
                "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
                "\n",
                "print(f'TensorFlow version: {tf.__version__}')\n",
                "print(f'GPU available: {len(tf.config.list_physical_devices(\"GPU\")) > 0}')\n",
                "\n",
                "BASE_DIR   = Path(r'c:\\Users\\saigo\\Desktop\\fraud_document_ai')\n",
                "TRAIN_DIR  = BASE_DIR / 'dataset' / 'train'\n",
                "VAL_DIR    = BASE_DIR / 'dataset' / 'val'\n",
                "TEST_DIR   = BASE_DIR / 'dataset' / 'test'\n",
                "MODEL_PATH = str(BASE_DIR / 'models' / 'fraud_document_cnn.h5')\n",
                "\n",
                "IMG_SIZE  = 128\n",
                "BATCH     = 32\n",
                "EPOCHS    = 30\n",
                "\n",
                "# Verify directories\n",
                "for d in [TRAIN_DIR, VAL_DIR, TEST_DIR]:\n",
                "    t = len(list((d/'fraud').iterdir()))\n",
                "    g = len(list((d/'genuine').iterdir()))\n",
                "    print(f'{d.name}: fraud={t}, genuine={g}, total={t+g}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "nb16-0003",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ── Data generators with augmentation ───────────────────────────────────────\n",
                "\n",
                "train_datagen = ImageDataGenerator(\n",
                "    rescale=1./255,\n",
                "    rotation_range=5,\n",
                "    width_shift_range=0.05,\n",
                "    height_shift_range=0.05,\n",
                "    zoom_range=0.05,\n",
                "    horizontal_flip=False,   # bills should not be flipped\n",
                "    fill_mode='nearest'\n",
                ")\n",
                "\n",
                "val_datagen = ImageDataGenerator(rescale=1./255)\n",
                "\n",
                "train_gen = train_datagen.flow_from_directory(\n",
                "    str(TRAIN_DIR),\n",
                "    target_size=(IMG_SIZE, IMG_SIZE),\n",
                "    color_mode='grayscale',\n",
                "    batch_size=BATCH,\n",
                "    class_mode='binary',\n",
                "    classes=['fraud', 'genuine'],   # fraud=0, genuine=1\n",
                "    shuffle=True,\n",
                "    seed=42\n",
                ")\n",
                "\n",
                "val_gen = val_datagen.flow_from_directory(\n",
                "    str(VAL_DIR),\n",
                "    target_size=(IMG_SIZE, IMG_SIZE),\n",
                "    color_mode='grayscale',\n",
                "    batch_size=BATCH,\n",
                "    class_mode='binary',\n",
                "    classes=['fraud', 'genuine'],\n",
                "    shuffle=False\n",
                ")\n",
                "\n",
                "print(f'\\nClass indices: {train_gen.class_indices}')\n",
                "print(f'Train batches: {len(train_gen)}  |  Val batches: {len(val_gen)}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "nb16-0004",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ── CNN Architecture ─────────────────────────────────────────────────────────\n",
                "# 4-block CNN with batch norm and dropout — designed for CPU training\n",
                "\n",
                "def build_cnn(img_size=128):\n",
                "    model = models.Sequential([\n",
                "        # Block 1\n",
                "        layers.Conv2D(32, (3,3), activation='relu', padding='same',\n",
                "                      input_shape=(img_size, img_size, 1)),\n",
                "        layers.BatchNormalization(),\n",
                "        layers.MaxPooling2D(2,2),\n",
                "\n",
                "        # Block 2\n",
                "        layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
                "        layers.BatchNormalization(),\n",
                "        layers.MaxPooling2D(2,2),\n",
                "        layers.Dropout(0.25),\n",
                "\n",
                "        # Block 3\n",
                "        layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
                "        layers.BatchNormalization(),\n",
                "        layers.MaxPooling2D(2,2),\n",
                "        layers.Dropout(0.25),\n",
                "\n",
                "        # Block 4\n",
                "        layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
                "        layers.BatchNormalization(),\n",
                "        layers.GlobalAveragePooling2D(),\n",
                "\n",
                "        # Classifier\n",
                "        layers.Dense(128, activation='relu'),\n",
                "        layers.Dropout(0.4),\n",
                "        layers.Dense(1, activation='sigmoid')   # 0=fraud, 1=genuine\n",
                "    ])\n",
                "    return model\n",
                "\n",
                "model = build_cnn(IMG_SIZE)\n",
                "model.summary()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "nb16-0005",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ── Compile ──────────────────────────────────────────────────────────────────\n",
                "\n",
                "model.compile(\n",
                "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
                "    loss='binary_crossentropy',\n",
                "    metrics=['accuracy',\n",
                "             tf.keras.metrics.Precision(name='precision'),\n",
                "             tf.keras.metrics.Recall(name='recall')]\n",
                ")\n",
                "\n",
                "# Callbacks\n",
                "checkpoint_cb = callbacks.ModelCheckpoint(\n",
                "    MODEL_PATH,\n",
                "    monitor='val_accuracy',\n",
                "    save_best_only=True,\n",
                "    verbose=1\n",
                ")\n",
                "earlystop_cb = callbacks.EarlyStopping(\n",
                "    monitor='val_accuracy',\n",
                "    patience=6,\n",
                "    restore_best_weights=True,\n",
                "    verbose=1\n",
                ")\n",
                "reduce_lr_cb = callbacks.ReduceLROnPlateau(\n",
                "    monitor='val_loss',\n",
                "    factor=0.5,\n",
                "    patience=3,\n",
                "    verbose=1,\n",
                "    min_lr=1e-6\n",
                ")\n",
                "\n",
                "print('✅ Model compiled')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "nb16-0006",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ── Compute class weights (handle imbalance) ─────────────────────────────────\n",
                "\n",
                "n_fraud   = len(list((TRAIN_DIR/'fraud').iterdir()))\n",
                "n_genuine = len(list((TRAIN_DIR/'genuine').iterdir()))\n",
                "total     = n_fraud + n_genuine\n",
                "\n",
                "# fraud=0, genuine=1\n",
                "class_weights = {\n",
                "    0: total / (2 * n_fraud),\n",
                "    1: total / (2 * n_genuine)\n",
                "}\n",
                "print(f'Class weights: {class_weights}')\n",
                "print(f'  (fraud weight {class_weights[0]:.2f} vs genuine {class_weights[1]:.2f})')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "nb16-0007",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ── Train ────────────────────────────────────────────────────────────────────\n",
                "# ⚠️  CPU training: ~3-5 min/epoch × 30 epochs max → ~1.5hrs worst case\n",
                "# EarlyStopping typically kicks in at epoch 10-15 → ~45min\n",
                "\n",
                "print('Starting training... (this will take ~30-90 min on CPU)')\n",
                "print('Best model will be saved to:', MODEL_PATH)\n",
                "\n",
                "history = model.fit(\n",
                "    train_gen,\n",
                "    epochs=EPOCHS,\n",
                "    validation_data=val_gen,\n",
                "    class_weight=class_weights,\n",
                "    callbacks=[checkpoint_cb, earlystop_cb, reduce_lr_cb],\n",
                "    verbose=1\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "nb16-0008",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ── Plot training curves ─────────────────────────────────────────────────────\n",
                "\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
                "\n",
                "axes[0].plot(history.history['accuracy'],     label='Train Acc',  color='#58a6ff')\n",
                "axes[0].plot(history.history['val_accuracy'], label='Val Acc',    color='#3fb950')\n",
                "axes[0].axhline(0.85, color='#f85149', linestyle='--', label='Target 85%')\n",
                "axes[0].set_title('Accuracy', fontsize=13)\n",
                "axes[0].set_xlabel('Epoch')\n",
                "axes[0].legend()\n",
                "axes[0].set_ylim([0, 1])\n",
                "\n",
                "axes[1].plot(history.history['loss'],     label='Train Loss', color='#58a6ff')\n",
                "axes[1].plot(history.history['val_loss'], label='Val Loss',   color='#3fb950')\n",
                "axes[1].set_title('Loss', fontsize=13)\n",
                "axes[1].set_xlabel('Epoch')\n",
                "axes[1].legend()\n",
                "\n",
                "plt.tight_layout()\n",
                "\n",
                "reports_dir = BASE_DIR / 'reports'\n",
                "reports_dir.mkdir(exist_ok=True)\n",
                "plt.savefig(str(reports_dir / 'training_curves.png'), dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "print('✅ Training curves saved to reports/training_curves.png')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "nb16-0009",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ── Evaluate on test set ─────────────────────────────────────────────────────\n",
                "\n",
                "test_gen = val_datagen.flow_from_directory(\n",
                "    str(TEST_DIR),\n",
                "    target_size=(IMG_SIZE, IMG_SIZE),\n",
                "    color_mode='grayscale',\n",
                "    batch_size=BATCH,\n",
                "    class_mode='binary',\n",
                "    classes=['fraud', 'genuine'],\n",
                "    shuffle=False\n",
                ")\n",
                "\n",
                "results = model.evaluate(test_gen, verbose=1)\n",
                "print(f'\\n=== CNN Test Results ===')\n",
                "print(f'  Accuracy:  {results[1]:.4f} ({results[1]*100:.1f}%)')\n",
                "print(f'  Precision: {results[2]:.4f}')\n",
                "print(f'  Recall:    {results[3]:.4f}')\n",
                "\n",
                "best_val_acc = max(history.history['val_accuracy'])\n",
                "print(f'  Best Val Accuracy: {best_val_acc:.4f} ({best_val_acc*100:.1f}%)')\n",
                "print(f'  Model saved to: {MODEL_PATH}')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.19"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}